Across this discussion, a clear theme has emerged: deep learning technologies, both generative and non-generative, offer immense potential, but they also raise significant ethical, legal, and societal challenges. My initial post emphasised how convolutional and transformer architectures now underpin diverse systems, from diagnostic imaging (Esteva et al., 2017) to text generation models such as ChatGPT, Gemini, and Claude. While these technologies improve efficiency and accessibility, they also risk bias, misinformation, and environmental impact (Nasim, Ali and Kulsoom, 2022).

Ana-Maria’s post deepened the debate by highlighting the psychological and social implications of hyper-realistic AI media. I agreed that misinformation and deepfakes erode trust and can harm vulnerable groups, especially young users. In my response, I suggested preventive measures, including content-provenance frameworks (C2PA, 2024), licensing transparency for creative works, and targeted media literacy education.

Pëllumb raised the issue of authorship and copyright in generative systems. I built on that discussion by noting that dataset documentation (Bender and Friedman, 2018) and fairness auditing could enhance accountability. Regulatory clarity and bias mitigation must accompany technological progress.

Taken together, these exchanges reinforced that the core ethical tension lies not in whether deep learning should advance, but in how it is governed. Transparency, dataset traceability, and user education are essential to ensure innovation remains aligned with human values and creativity.

### References
Bender, E.M. and Friedman, B. (2018) ‘Data statements for natural language processing: Toward mitigating system bias and enabling better science’, Transactions of the Association for Computational Linguistics, 6, pp. 587–604. Available at: https://aclanthology.org/Q18-1041/ (Accessed: 13 October 2025).

C2PA (2024) Technical specifications for content provenance and authenticity v1.3. Available at: https://c2pa.org/specifications/ (Accessed: 13 October 2025).

Esteva, A. et al. (2017) ‘Dermatologist-level classification of skin cancer with deep neural networks’, Nature, 542, pp. 115–118. Available at: https://www.nature.com/articles/nature21056 (Accessed: 13 October 2025).

Nasim, S.F., Ali, M.R. and Kulsoom, U. (2022) ‘Artificial intelligence incidents & ethics: a narrative review’, International Journal of Technology, Innovation and Management, 2(2), pp. 52–64. Available at: https://journals.gaftim.com/index.php/ijtim/article/view/80 (Accessed: 7 October 2025).
