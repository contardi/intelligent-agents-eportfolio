by Pëllumb Dalipi

Deep learning now produces various content such as text, images or music that appear human-made. These developments do create a central issue in the consideration of authorship. Generative systems rely on vast datasets of content that was initially created by humans. The link between those inputs and ownership of outputs is unclear, which strains copyright’s tests for human creativity and control (Lim, 2023; Al-Busaidi, 2024).

Copyright however is not the only question of concern. Authenticity is another topic that is currently debated in academia as well as the public. AI-generated media can erode trust if audiences cannot tell who or what made a piece of content. Research on deepfakes shows risks for journalism and public communication, including confusion and lowered credibility (Lundberg, 2024; Raemy, 2025). Bias in training data can be an additional harm. If training data encode skewed patterns, models can reproduce them and widen inequities in sensitive domains (Ukanwa, 2024; Wei, 2025).

However, there are also potential benefits to those working in media. Experiments find that access to generative tools can raise the average quality of creative work and help less experienced writers and artists participate (Doshi et al., 2024). This potential upside depends on safeguard though, which can be achieved by disclosing the involvement of AI, documenting the used datasets and routes for attribution.

### References


Al-Busaidi, A. S. (2024). Investigating the impact of generative artificial intelligence on creative industries. Heliyon.

Doshi, A. R., et al. (2024). Generative AI enhances individual creativity but reduces variance. Science Advances.

Lim, D. (2023). Generative AI and copyright. Journal of Intellectual Property Law & Practice.

Lundberg, E. (2024). The potential effects of deepfakes on news media. AI & Society.

Raemy, P. (2025). Deepfakes and journalism. Journalism Studies.

Ukanwa, K. (2024). Algorithmic bias and social science integration. Journal of Behavioral and Experimental Economics.

Wei, X., et al. (2025). Addressing bias in generative AI. Information & Management.

--------

## Peer Response

Hi Pëllumb,

You’ve drawn a vital connection between authorship, authenticity, and bias in deep learning. I agree that generative systems challenge existing copyright frameworks because ownership of model outputs rarely maps cleanly to human creativity or control (Lim, 2023). One practical response may be to expand dataset disclosure and traceability, similar to data statements used in natural language processing, which describe dataset origins, licences, and demographic composition. Such transparency would help regulators and creators assess whether AI-generated outputs derive from protected material (Bender and Friedman, 2018).

Your mention of bias is also crucial. Studies demonstrate that even minor imbalances in training data can propagate systemic inequities when deployed at scale. Bias mitigation, therefore, needs to occur at multiple stages: pre-processing (balancing or anonymising datasets), in-training (fairness-aware loss functions), and post-processing (auditing model outputs) (Mehrabi et al., 2021).

Regarding authenticity, I agree with your suggestion that disclosure of AI involvement is essential. Complementary technical measures, such as watermarking and content provenance standards, can ensure accountability while protecting genuine creative uses (C2PA, 2024). This layered approach of transparency, fairness, and traceability not only preserves public trust but also allows creative industries to integrate generative AI responsibly.

Your post highlights that the question is not whether deep learning should contribute to creative work, but how we can govern it to respect both innovation and human authorship.

### References  

Bender, E.M. and Friedman, B. (2018) ‘Data statements for natural language processing: Toward mitigating system bias and enabling better science’, Transactions of the Association for Computational Linguistics, 6, pp. 587–604. Available at: https://aclanthology.org/Q18-1041/ (Accessed: 13 October 2025).

C2PA (2024) Technical specifications for content provenance and authenticity v1.3. Available at: https://c2pa.org/specifications/ (Accessed: 13 October 2025).

Lim, D. (2023). Generative AI and copyright. Journal of Intellectual Property Law & Practice.

Mehrabi, N. et al. (2021) ‘A survey on bias and fairness in machine learning’, ACM Computing Surveys, 54(6), pp. 1–35. doi:10.1145/3457607. Available at: https://dl.acm.org/doi/10.1145/3457607 (Accessed: 13 October 2025).
